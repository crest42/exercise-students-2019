{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys\n",
    "from sklearn import linear_model, datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1.1 Create a classification model using a logistic regression!\n",
    "\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "* Train a model using a testing dataset of 25%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 0, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 2,\n",
       "       1, 0, 2, 1, 1, 1, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 1, 0, 1, 2, 1,\n",
       "       0, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 1, 2,\n",
       "       2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 2, 1, 2, 1, 0, 2, 0, 2, 0, 0, 2, 0,\n",
       "       2, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 0, 1, 1, 2, 1, 0, 0, 0, 2, 1,\n",
       "       2, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "iris_df[\"target_name\"]=iris['target_names'][iris_df['target']] \n",
    "iris_df.head()\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "iris_df['target'] = iris.target\n",
    "iris_df[\"target_name\"]=iris['target_names'][iris_df['target']] \n",
    "iris_df.head()\n",
    "\n",
    "y = iris_df['target']\n",
    "X = iris_df.drop(['target','target_name'],1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "model = linear_model.LogisticRegression(solver = 'lbfgs',multi_class = 'auto',max_iter=1000)\n",
    "start = time.time()\n",
    "model.fit(X_train, y_train)\n",
    "runtime_sklearn = time.time()-start\n",
    "\n",
    "pred = model.predict(X_train)\n",
    "pred\n",
    "#model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualize the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a confusion matrix!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13,  0,  0],\n",
       "       [ 0, 15,  1],\n",
       "       [ 0,  0,  9]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_test,model.predict(X_test))\n",
    "conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute precision and recall for every class in your model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark initiated...\n"
     ]
    }
   ],
   "source": [
    "# Initialize PySpark\n",
    "import os, sys\n",
    "os.environ[\"JAVA_HOME\"]=\"/lrz/sys/compilers/java/jdk1.8.0_112\"\n",
    "APP_NAME = \"PySpark Lecture\"\n",
    "SPARK_MASTER=\"local[16]\"\n",
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import Row\n",
    "conf=pyspark.SparkConf()\n",
    "conf=pyspark.SparkConf().setAppName(APP_NAME).set(\"spark.local.dir\", os.path.join(os.getcwd(), \"tmp\"))\n",
    "sc = pyspark.SparkContext(master=SPARK_MASTER, conf=conf)\n",
    "spark = pyspark.sql.SparkSession(sc).builder.appName(APP_NAME).getOrCreate()\n",
    "\n",
    "print(\"PySpark initiated...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Spark MLlib to create a Logistic Regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|target2          |target|\n",
      "+-----------------+------+\n",
      "|[5.1,3.5,1.4,0.2]|0     |\n",
      "|[4.9,3.0,1.4,0.2]|0     |\n",
      "|[4.7,3.2,1.3,0.2]|0     |\n",
      "|[4.6,3.1,1.5,0.2]|0     |\n",
      "|[5.0,3.6,1.4,0.2]|0     |\n",
      "|[5.4,3.9,1.7,0.4]|0     |\n",
      "|[4.6,3.4,1.4,0.3]|0     |\n",
      "|[5.0,3.4,1.5,0.2]|0     |\n",
      "|[4.4,2.9,1.4,0.2]|0     |\n",
      "|[4.9,3.1,1.5,0.1]|0     |\n",
      "|[5.4,3.7,1.5,0.2]|0     |\n",
      "|[4.8,3.4,1.6,0.2]|0     |\n",
      "|[4.8,3.0,1.4,0.1]|0     |\n",
      "|[4.3,3.0,1.1,0.1]|0     |\n",
      "|[5.8,4.0,1.2,0.2]|0     |\n",
      "|[5.7,4.4,1.5,0.4]|0     |\n",
      "|[5.4,3.9,1.3,0.4]|0     |\n",
      "|[5.1,3.5,1.4,0.3]|0     |\n",
      "|[5.7,3.8,1.7,0.3]|0     |\n",
      "|[5.1,3.8,1.5,0.3]|0     |\n",
      "+-----------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "iris_df\n",
    "spark_df = spark.createDataFrame(iris_df)\n",
    "#dataset = iris_df\n",
    "\n",
    "#dataset = spark.createDataFrame(\n",
    "#    [(0, 18, 1.0, Vectors.dense([0.0, 10.0, 0.5]), 1.0)],\n",
    " #   [\"id\", \"hour\", \"mobile\", \"userFeatures\", \"clicked\"])\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"sepal length (cm)\", \"sepal width (cm)\", \"petal length (cm)\",\"petal width (cm)\"],\n",
    "    outputCol=\"target2\")\n",
    "\n",
    "output = assembler.transform(spark_df)\n",
    "output.select(\"target2\", \"target\").show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol = 'target2', labelCol = 'target', maxIter=10)\n",
    "start = time.time()\n",
    "train = lr.fit(output)\n",
    "runtime_spark = time.time() - start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Measure the training time. Compare the training time with the scikit-learn implementation! Explain! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime spark: 2.914445161819458\n",
      "Runtime sklearn: 0.0948183536529541\n"
     ]
    }
   ],
   "source": [
    "print(\"Runtime spark: \" + str(runtime_spark))\n",
    "print(\"Runtime sklearn: \" + str(runtime_sklearn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Idea why spark is so much slower, maybe bc of introduced overhead for setting up spark?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
